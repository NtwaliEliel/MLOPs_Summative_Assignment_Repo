{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# MNIST Image Classification - MLOps Pipeline\n",
                "\n",
                "This notebook demonstrates the complete ML pipeline for handwritten digit classification:\n",
                "1. Data Loading and Preprocessing\n",
                "2. Model Architecture Design\n",
                "3. Model Training with Callbacks\n",
                "4. Model Evaluation with Multiple Metrics\n",
                "5. Visualization of Results\n",
                "6. Model Saving"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import required libraries\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers\n",
                "from tensorflow.keras.datasets import mnist\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# Add parent directory to path\n",
                "sys.path.append(os.path.dirname(os.getcwd()))\n",
                "\n",
                "# Set style for visualizations\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "sns.set_palette('husl')\n",
                "\n",
                "print(f\"TensorFlow version: {tf.__version__}\")\n",
                "print(f\"Keras version: {keras.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading and Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load MNIST dataset\n",
                "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
                "\n",
                "print(f\"Training set shape: {x_train.shape}\")\n",
                "print(f\"Test set shape: {x_test.shape}\")\n",
                "print(f\"Number of classes: {len(np.unique(y_train))}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize sample images\n",
                "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
                "fig.suptitle('Sample MNIST Images', fontsize=16)\n",
                "\n",
                "for i, ax in enumerate(axes.flat):\n",
                "    ax.imshow(x_train[i], cmap='gray')\n",
                "    ax.set_title(f'Label: {y_train[i]}')\n",
                "    ax.axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Class distribution visualization\n",
                "plt.figure(figsize=(10, 6))\n",
                "unique, counts = np.unique(y_train, return_counts=True)\n",
                "plt.bar(unique, counts, color='steelblue', edgecolor='black')\n",
                "plt.xlabel('Digit Class', fontsize=12)\n",
                "plt.ylabel('Frequency', fontsize=12)\n",
                "plt.title('Training Data Class Distribution', fontsize=14)\n",
                "plt.xticks(unique)\n",
                "plt.grid(axis='y', alpha=0.3)\n",
                "plt.show()\n",
                "\n",
                "print(\"Class distribution:\")\n",
                "for digit, count in zip(unique, counts):\n",
                "    print(f\"Digit {digit}: {count} samples ({count/len(y_train)*100:.2f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preprocess data\n",
                "# Normalize pixel values to [0, 1]\n",
                "x_train = x_train.astype('float32') / 255.0\n",
                "x_test = x_test.astype('float32') / 255.0\n",
                "\n",
                "# Reshape to include channel dimension\n",
                "x_train = x_train.reshape(-1, 28, 28, 1)\n",
                "x_test = x_test.reshape(-1, 28, 28, 1)\n",
                "\n",
                "# Create validation split\n",
                "val_split = 0.1\n",
                "val_size = int(len(x_train) * val_split)\n",
                "\n",
                "x_val = x_train[:val_size]\n",
                "y_val = y_train[:val_size]\n",
                "x_train = x_train[val_size:]\n",
                "y_train = y_train[val_size:]\n",
                "\n",
                "print(f\"Training set: {x_train.shape}\")\n",
                "print(f\"Validation set: {x_val.shape}\")\n",
                "print(f\"Test set: {x_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Model Architecture"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create CNN model\n",
                "model = keras.Sequential([\n",
                "    # First convolutional block\n",
                "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
                "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
                "    layers.BatchNormalization(),\n",
                "    \n",
                "    # Second convolutional block\n",
                "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
                "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
                "    layers.BatchNormalization(),\n",
                "    \n",
                "    # Third convolutional block\n",
                "    layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
                "    layers.BatchNormalization(),\n",
                "    \n",
                "    # Flatten and dense layers\n",
                "    layers.Flatten(),\n",
                "    layers.Dropout(0.5),\n",
                "    layers.Dense(128, activation='relu'),\n",
                "    layers.Dropout(0.3),\n",
                "    layers.Dense(10, activation='softmax')\n",
                "])\n",
                "\n",
                "# Compile model\n",
                "model.compile(\n",
                "    optimizer='adam',\n",
                "    loss='sparse_categorical_crossentropy',\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "# Display model architecture\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define callbacks\n",
                "early_stopping = EarlyStopping(\n",
                "    monitor='val_loss',\n",
                "    patience=5,\n",
                "    restore_best_weights=True,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "model_checkpoint = ModelCheckpoint(\n",
                "    '../models/cnn_model.h5',\n",
                "    monitor='val_accuracy',\n",
                "    save_best_only=True,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "# Train model\n",
                "history = model.fit(\n",
                "    x_train, y_train,\n",
                "    batch_size=128,\n",
                "    epochs=20,\n",
                "    validation_data=(x_val, y_val),\n",
                "    callbacks=[early_stopping, model_checkpoint],\n",
                "    verbose=1\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot training history\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Accuracy plot\n",
                "ax1.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
                "ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
                "ax1.set_xlabel('Epoch', fontsize=12)\n",
                "ax1.set_ylabel('Accuracy', fontsize=12)\n",
                "ax1.set_title('Model Accuracy Over Epochs', fontsize=14)\n",
                "ax1.legend()\n",
                "ax1.grid(alpha=0.3)\n",
                "\n",
                "# Loss plot\n",
                "ax2.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
                "ax2.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
                "ax2.set_xlabel('Epoch', fontsize=12)\n",
                "ax2.set_ylabel('Loss', fontsize=12)\n",
                "ax2.set_title('Model Loss Over Epochs', fontsize=14)\n",
                "ax2.legend()\n",
                "ax2.grid(alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Evaluation with Multiple Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make predictions on test set\n",
                "y_pred_probs = model.predict(x_test)\n",
                "y_pred = np.argmax(y_pred_probs, axis=1)\n",
                "\n",
                "# Calculate metrics\n",
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "precision = precision_score(y_test, y_pred, average='weighted')\n",
                "recall = recall_score(y_test, y_pred, average='weighted')\n",
                "f1 = f1_score(y_test, y_pred, average='weighted')\n",
                "\n",
                "print(\"=\"*50)\n",
                "print(\"MODEL EVALUATION METRICS\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
                "print(f\"Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
                "print(f\"Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
                "print(f\"F1 Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
                "print(\"=\"*50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Per-class metrics\n",
                "from sklearn.metrics import classification_report\n",
                "\n",
                "print(\"\\nPer-Class Classification Report:\")\n",
                "print(classification_report(y_test, y_pred, target_names=[str(i) for i in range(10)]))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Confusion Matrix Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute confusion matrix\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "\n",
                "# Plot confusion matrix\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
                "            xticklabels=range(10), yticklabels=range(10))\n",
                "plt.xlabel('Predicted Label', fontsize=12)\n",
                "plt.ylabel('True Label', fontsize=12)\n",
                "plt.title('Confusion Matrix - MNIST Classification', fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Normalized confusion matrix\n",
                "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='RdYlGn', cbar=True,\n",
                "            xticklabels=range(10), yticklabels=range(10))\n",
                "plt.xlabel('Predicted Label', fontsize=12)\n",
                "plt.ylabel('True Label', fontsize=12)\n",
                "plt.title('Normalized Confusion Matrix', fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Sample Predictions Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize correct and incorrect predictions\n",
                "correct_indices = np.where(y_pred == y_test)[0]\n",
                "incorrect_indices = np.where(y_pred != y_test)[0]\n",
                "\n",
                "# Plot correct predictions\n",
                "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
                "fig.suptitle('Correct Predictions', fontsize=16)\n",
                "\n",
                "for i, ax in enumerate(axes.flat):\n",
                "    idx = correct_indices[i]\n",
                "    ax.imshow(x_test[idx].reshape(28, 28), cmap='gray')\n",
                "    ax.set_title(f'True: {y_test[idx]}, Pred: {y_pred[idx]}\\nConf: {y_pred_probs[idx][y_pred[idx]]:.2f}')\n",
                "    ax.axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Plot incorrect predictions\n",
                "if len(incorrect_indices) > 0:\n",
                "    fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
                "    fig.suptitle('Incorrect Predictions', fontsize=16)\n",
                "    \n",
                "    for i, ax in enumerate(axes.flat):\n",
                "        if i < len(incorrect_indices):\n",
                "            idx = incorrect_indices[i]\n",
                "            ax.imshow(x_test[idx].reshape(28, 28), cmap='gray')\n",
                "            ax.set_title(f'True: {y_test[idx]}, Pred: {y_pred[idx]}\\nConf: {y_pred_probs[idx][y_pred[idx]]:.2f}', color='red')\n",
                "            ax.axis('off')\n",
                "        else:\n",
                "            ax.axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"No incorrect predictions found!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Model Saving"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save final model\n",
                "model_path = '../models/cnn_model.h5'\n",
                "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
                "model.save(model_path)\n",
                "print(f\"Model saved to {model_path}\")\n",
                "\n",
                "# Verify model can be loaded\n",
                "loaded_model = keras.models.load_model(model_path)\n",
                "print(\"Model loaded successfully!\")\n",
                "\n",
                "# Verify loaded model predictions\n",
                "test_pred = loaded_model.predict(x_test[:5])\n",
                "print(\"\\nTest predictions from loaded model:\")\n",
                "print(np.argmax(test_pred, axis=1))\n",
                "print(\"True labels:\")\n",
                "print(y_test[:5])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "This notebook demonstrated a complete MLOps pipeline for MNIST digit classification:\n",
                "\n",
                "1. **Data Preprocessing**: Loaded and normalized MNIST dataset\n",
                "2. **Model Architecture**: Built a CNN with 3 convolutional blocks\n",
                "3. **Training**: Used early stopping and model checkpointing\n",
                "4. **Evaluation**: Calculated 4 key metrics (Accuracy, Precision, Recall, F1)\n",
                "5. **Visualization**: Created confusion matrix and training curves\n",
                "6. **Model Persistence**: Saved model as .h5 file\n",
                "\n",
                "The model achieves excellent performance and is ready for deployment!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}